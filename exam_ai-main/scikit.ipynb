{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d21aef0",
   "metadata": {},
   "source": [
    "# Exam question - course outcome matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cb5e0",
   "metadata": {},
   "source": [
    "Author: Mertcan Atay<br>\n",
    "Repo: https://github.com/mertcanfsm/exam_ai<br>\n",
    "\n",
    "Using limited text data to predict class label.<br>\n",
    "\n",
    "<ul>\n",
    "    <li>Dataset size:</li>\n",
    "        <ul>\n",
    "            <li>Very small (&lt 20 samples / Turkish)</li>\n",
    "            <li>Small (&lt 150 samples / English)</li>\n",
    "        </ul>\n",
    "    <li>Word embeddings</li>\n",
    "        <ul>\n",
    "            <li>Tfidf</li>\n",
    "            <li>Word2vec</li>\n",
    "        </ul>\n",
    "    <li>Model selection</li>\n",
    "        <ul>\n",
    "            <li>Train-test split</li>\n",
    "            <li>Leave one out</li>\n",
    "        </ul>\n",
    "    <li>Machine learning models</li>\n",
    "        <ul>\n",
    "            <li>MultinomialNB</li>\n",
    "            <li>LogisticRegression</li>\n",
    "            <li>LinearSVC</li>\n",
    "            <li>RandomForestClassifier</li>\n",
    "        </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9d3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocess import preprocess\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc85b7",
   "metadata": {},
   "source": [
    "Choose one of the following word2vec models (if word2vec is choosen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa1bf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69133"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small Turkish word2vec model (https://www.kaggle.com/murats/word2vec-application-on-turkish-newspaper/notebook)\n",
    "w2v = Word2Vec.load(\"word2vec_small\").wv\n",
    "keys = w2v.index_to_key\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d8e66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412457"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Big Turkish word2vec model (https://github.com/akoksal/Turkish-Word2Vec)\n",
    "w2v = Word2Vec().wv.load_word2vec_format(\"word2vec_big\", binary=True)\n",
    "keys = w2v.index_to_key\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f037597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English word2vec model (https://github.com/eyaler/word2vec-slim)\n",
    "w2v = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300-SLIM.bin\", binary=True)\n",
    "keys = w2v.index_to_key\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7e698",
   "metadata": {},
   "source": [
    "Word2vec preprocessing for sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_w2v(tokens,w2v,keys):\n",
    "    # Remove words not in word2vec model\n",
    "    for i in range(len(tokens)):\n",
    "        word = tokens[i]\n",
    "        if word in keys:\n",
    "            tokens[i] = w2v[word]\n",
    "        else:\n",
    "            tokens[i] = None\n",
    "    tokens = list(filter(lambda x: hasattr(x,\"__len__\"), tokens))\n",
    "\n",
    "    # Calculate the average vector of the sentence words\n",
    "    vec_avg = []\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(w2v.vector_size)\n",
    "    dim = len(tokens[0])\n",
    "    sen_len = len(tokens)\n",
    "    for i in range(dim):\n",
    "        total = 0\n",
    "        for j in range(sen_len):\n",
    "            total += tokens[j][i]\n",
    "        vec_avg.append(total / sen_len)\n",
    "    return vec_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063505ed",
   "metadata": {},
   "source": [
    "Choose one of the two datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fc6fe",
   "metadata": {},
   "source": [
    "<b>1- Example exam questions and their respective course outcome IDs.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    'Verilen 5x5’lük dizi içinde her satırda -1 özel rakamı arasında kalan sayıların toplamını ekrana yazdıran algoritmanın kodunu yazınız ve akış diyagramını çiziniz. Satırda -1 yoksa 0 yazacaktır. (ipucu ilk satırda 9 ikinci satırda 18 yazacak.) a şıkkındaki algoritmayı sadece -1 geçen (toplamı 0 olmayan) satırları bir Arraylist’e aktaracak şekilde düzenleyiniz.',\n",
    "    'Aşağıdaki sınıf yapısını kodlayınız. İsmi verilen metotlar sorulardaki ihtiyaçlara göre düzenlenmelidir. Metot içinde nesnenin gerekli özellikleri kullanılmalıdır.  Personel  adi alanını ilk atamadan sonra sabit yapınız. Her sınıf kendi ismini taşıyan paketteyse BirimUnvan sınıfı içinde Memur sınıfına erişmek için gerekli import kodunu yazınız. toplamMaas özelliğini sınıf değişkeni yapınız. Personel sınıfı unvanlar özelliğini unvan nesnesi tutan bir array olarak gerçekleştiriniz. Dizide 10 adet unvan saklanabilecek şekilde ilk değer veriniz.  Personel sınıfı adresler özelliğini String tutan bir ArrayList olarak gerçekleştiriniz. getUnvanMaas metodunu YoneticiUnvan sınıflarda maaş değerinin %20 fazlasını döndürecek şekilde özelleştiriniz(override). YoneticiUnvan ve BirimUnvan türlerinde iki parametre alan, bunları bir diziye ekleyen ve bu diziyi döndüren bir metodun tanımını(imzasını) yazınız. Metodun gerçekleştirilmesine gerek yoktur.',\n",
    "    'İkinci Sorudaki Modeli kullanarak getPersonelMaas metodunu kullanarak unvanlar dizisi üzerinden personele ödenen toplam maaşı yazdırınız. IMaasHesap isimli bir interface oluşturunuz.  Bu interface’de unvanEkle(Unvan u) metodu olacaktır. Personel sınıfı içerisinde IMaasHesap interface’ini gerçekleştiren bir statik gömülü sınıf oluşturunuz. Bu gömülü sınıfta personelin unvanlar dizisine her unvan eklendiğinde toplam maaşı unvanın maas özelliği kadar arttıracak kodu yazınız. Bu metotları test sınıfından çağırınız.  Personel sınıfına parametre olarak gönderilen adresi adresler ArrayList’ine ekleyecek şekilde bir yapıcı (costructor) metodu ekleyiniz. Memur sınıfı içerisinde bir iç sınıf kullanarak adresler dizisindeki adresleri satır satır yazdıran bir metodu kodlayınız. Bu metotları test sınıfından çağıran kodu yazınız.',\n",
    "    'Aşağıdaki kodun doğru çalışması için IX arayüzü ve sinifA’yı metotlarının sadece tanımları(imzaları) olarak şekilde yazınız. SinifA IX arayüzünü gerçekleştirmektedir.',\n",
    "    'Gömülü sınıf, iç sınıf ve yerel sınıf kavramlarını tanımlayınız ve kısaca örnekleyiniz. Soyut sınıfın ara yüze(interface) göre üstünlüklerini açıklayınız Çok biçimlilik ve metot aşırı yükleme (overloading) ilişkisini açıklayınız.',\n",
    "    'Verilen dizi içinde yan yana aynı değerlere sahip sütunların değerlerini yazdıran algoritmanın kodunu yazınız ve akış diyagramını çiziniz. Algoritma satır sayısı çok fazla olan durumlarda da çalışmalıdır. Sınırlara dikkat ediniz. İlk satırla aynı değerleri taşıyan sütunların adedini ilk sütunla yan yana olmasa da bulan algoritmayı yazınız.',\n",
    "    'Aşağıdaki sınıf yapısını kodlayınız. İsmi verilen metotlar sorulardaki ihtiyaçlara göre düzenlenmelidir. Metot içinde nesnenin gerekli özellikleri kullanılmalıdır. Tüm şıklar kodun yanında belirtilmelidir. Mesai sınıfını alt sınıf üretilemez hale getiriniz. Kamu sınıfına kamuNo alanına değer atayan bir yapıcı metot ekleyiniz. Hastane sınıfına arayüz yapmak için modelde ne tür değişiklikler yapılmalıdır. Hizmetlinin görev niteliğini sadece kendi sınıfı içinde gözükebilen hale getiriniz. Hastane adres niteliğini hiçbir örnekte ve sınıf düzeyinde değiştirilemez yapınız. Kisi sınıfını soyut sınıf yapmak için modelde ne tür değişiklikler yapılmalıdır.',\n",
    "    'İkinci Sorudaki Modeli kullanarak Doktor sınıfına herhangi bir sayıda Mesai nesnesi alan ve bunları mesaiListesine ekleyen bir metot ekleyiniz. getKısıUcret() metodu ile kişinin çalıştığı aylar üzerinden kişiye ödenen toplam ücreti bulunuz. mesiaGoster() metodunu kullanarak Doktor sadece özel hastanede çalışıyorsa toplam mesaisini döndürecek şekilde gerçekleştiriniz. mesaiUcreti saat cinsindendir. (İpucu: Nesne türü bulmak kullanılmalıdır.) getKısıUcret() metodunu Doktor sınıfında override ederek toplam mesai de eklenmiş ücreti bulacak hale getiriniz.  Hastane sınıfına kaç adet doktorun kamu ve özel hastanelerde çalıştığını bulan bir metot ekleyiniz.',\n",
    "    'Aşağıdaki kodun doğru çalışması için gerekli arayüz ve sınıfları tanımlayınız? IKisi bir arayüzdür.  Kısaca açıklayınız. Metotların aldıkları değişken türlerine dikkat ediniz.',\n",
    "    'Kapsüllemeyi (encapsulation) tanımlayınız. Faydalarını açıklayınız. Aşağı ve yukarı dönüşüm işlemlerini kısaca tanımlayınız. Niçin kullanıldıklarını açıklayınız. Dinamik metot bağlama ve çok biçimlilik ilişkisini açıklayınız.',\n",
    "    'Verilen 5x5’lik dizi içinde yan yana numaraların adet ve toplamını gösteren algoritmanın kodunu yazınız ve akış diyagramını çiziniz. Sınırlara dikkat ediniz. Yan yana rakamların toplamlarını bir diziye aktarınız. Örneğin dizide 1 rakamı için 3, 85 rakamı için 10 tutulmalıdır. İpucu rakamlar dizi indisi olarak kullanılabilir.',\n",
    "    'Aşağıdaki sınıf yapısını kodlayınız. İsmi verilen metotlar sorulardaki ihtiyaçlara göre düzenlenmelidir. Metot içinde nesnenin gerekli özellikleri kullanılmalıdır. Tüm şıklar kodun yanında belirtilmelidir. IDers arayüzünü tüm paketlerde görünür yapınız. Oğrenci sınıfı ayrı bir kisi.ogrenci paketindeyse bunu Matematik sınıfından referans etmek için gerekli import kodunuz yazınız.  Bolum  özelliğinin tüm malzeme örneklerinde (instance) aynı değeri taşıması için gerekli kodu yazınız.  Matematik sınıfındaki adi özelliğini tüm paketlerdeki alt sınıflarda görünür yapmak için gerekli kodu yazınız. Alt sınıflarda üst sınıf özelliğine ulaşan örnek bir kod yazınız. Ogrenci sınıfında adi niteliğini alan bir yapıcı metot ekleyiniz. Ogrenci sınıfindan bilgisayarOğrencisi sınıfı kalıtılırsa yapıcıların doğru çalışması için yapılması gerekenleri yazınız.',\n",
    "    'İkinci Sorudaki Modeli kullanarak OgrenciDers sınıfındaki  getNotOrtalama()  metodunu dersin ortalama notunu bulacak şekilde gerçekleştiriniz.  getHarf Not metodu bu sınıfta gerçekleştirilmemelidir. Ogrenci sınıfındaki  getNotOrtalama()  metodunu öğrencinin tüm derslerdeki ortalama notunu bulacak şekilde gerçekleştiriniz.   Matematik sınıfında getNotOrtalama metodunu öğrencinin tüm derslerden aldığı not ortalamasını odev notunu da ekleyecek şekilde özelleştiriniz.  IDers arayüzündeki getNotOrtalama() metodunu not sistemini de alacak şekilde overload ediniz.  VeriYapilari sınıfında getHaftNot metodunu  NotSistemi nesnesi alacak, NotSistemi yüzlükse ve ortalaması  90 üzeri öğrencileri için  AA,  diğer durumda XX döndürecek şekilde gerçekleştiriniz. Ogrenciye ders ve not ekleyerek b şıkkını test eden kodu yazınız.',\n",
    "    'Aşağıdaki kodun doğru çalışması için gerekli sınıfları tanımlayınız? Kısaca açıklayınız.',\n",
    "    'Sınıflar arası kalıtım ve arayüz kullanımını karşılaştırınız. Bunlar birbiri yerine kullanılabilir mi ve kullanılırsa ne tür olumsuz olumsuz durumlar oluşur belirtiniz.  Gömülü sınıflarda kalıtım kullanımının sağlayacağı faydaları açıklayınız. Arayüzü sınıftan ayıran özellikleri açıklayınız.'\n",
    "])\n",
    "y = np.array([4,3,1,2,0,4,3,1,2,1,4,3,1,2,0])\n",
    "language = 'turkish'\n",
    "course_name = 'BLM19103'\n",
    "stem = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ecbd41",
   "metadata": {},
   "source": [
    "<b>2- For performance testing purposes, a bigger text dataset for classification purposes.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdd53d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv('questions_processed.csv'))\n",
    "X = df[df.columns[0]].to_numpy()\n",
    "y = df[df.columns[1]].to_numpy()\n",
    "language = 'english'\n",
    "course_name = 'GCSE_CS'\n",
    "stem = True\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa34991",
   "metadata": {},
   "source": [
    "Example prediction sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Verilen 5x5’lük dizi içinde her satırda -1 özel rakamı arasında kalan sayıların toplamını ekrana yazdıran algoritmanın kodunu yazınız ve akış diyagramını çiziniz. Satırda -1 yoksa 0 yazacaktır. (ipucu ilk satırda 9 ikinci satırda 18 yazacak.) Algoritma satır sayısı çok fazla olan durumlarda da çalışmalıdır. Sınırlara dikkat ediniz.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d2582",
   "metadata": {},
   "source": [
    "Choose tfidf or word2vec and preprocess text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c3f36",
   "metadata": {},
   "source": [
    "Data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029b407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tfidf:\n",
    "    X = [' '.join(preprocess(text,language,stem=stem)) for text in X]\n",
    "else:\n",
    "    X = [prepare_w2v(preprocess(text,language,stem=stem),w2v,keys) for text in X]\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Remove empty vectors\n",
    "if not tfidf:\n",
    "    is_zeros = []\n",
    "    for x in X:\n",
    "        is_zeros.append(np.logical_not(np.all(x == 0)))\n",
    "    X = X[is_zeros]\n",
    "    y = y[is_zeros]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4afb9",
   "metadata": {},
   "source": [
    "The train codes for both tfidf and word2vec training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfidf(model,X_train,X_test,y_train,y_test):\n",
    "    count_vect = CountVectorizer()\n",
    "    X_train_counts = count_vect.fit_transform(X_train)\n",
    "    X_test_counts = count_vect.transform(X_test)\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_trained = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "    clf = model.fit(X_trained, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_counts)\n",
    "    accuracy = (y_test == y_pred).sum() / X_test_counts.shape[0]\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def train_word2vec(model,X_train,X_test,y_train,y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    clf = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = (y_test == y_pred).sum() / X_test_scaled.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d80b9",
   "metadata": {},
   "source": [
    "The classification models to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41426e8",
   "metadata": {},
   "source": [
    "Finally, run the code by choosing one of the two data splitting methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0766b",
   "metadata": {},
   "source": [
    "<b>1- Train-test split</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c88ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "for model in models:\n",
    "    accuracy = 0\n",
    "    model_name = model.__class__.__name__\n",
    "    if tfidf:\n",
    "        accuracy = train_tfidf(model, X_train, X_test, y_train, y_test)\n",
    "    else:\n",
    "        accuracy = train_word2vec(model, X_train, X_test, y_train, y_test)\n",
    "    print(model_name + \" accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0634d7",
   "metadata": {},
   "source": [
    "<b>2- Leave one out</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850b026",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    i = 0\n",
    "    accuracy = 0\n",
    "    model_name = model.__class__.__name__\n",
    "    for train_index, test_index in LeaveOneOut().split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        if tfidf:\n",
    "            acc = train_tfidf(model, X_train, X_test, y_train, y_test)\n",
    "        else:\n",
    "            acc = train_word2vec(model, X_train, X_test, y_train, y_test)\n",
    "        accuracy += acc\n",
    "        i += 1\n",
    "    print(model_name + \" accuracy: \" + str(accuracy/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d82cea",
   "metadata": {},
   "source": [
    "<b>Bonus: Missing input words in word2vec model calculator</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032d79c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def word2vec_words_found(X,language,stem):\n",
    "    found = 0\n",
    "    missing = 0\n",
    "    for sentence in X:\n",
    "        for word in preprocess(sentence,language,stem=stem):\n",
    "            if word in keys:\n",
    "                found += 1\n",
    "            else:\n",
    "                missing += 1\n",
    "    return found/(found+missing)\n",
    "\n",
    "print(\"Found (with stemming): \" + str(word2vec_words_found(X,language,True)))\n",
    "print(\"Found (without stemming): \" + str(word2vec_words_found(X,language,False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069ea2a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c12af1",
   "metadata": {},
   "source": [
    "<i>(Below results were achieved with MultinomialNB model.)</i>\n",
    "<h2>Tfidf</h2>\n",
    "<h4>Turkish</h4>\n",
    "+ With stemming<br>\n",
    "- Train-test split accuracy: 0.25<br>\n",
    "- Leave-one-out split accuracy: 0.6166666666666667<br>\n",
    "+ Without stemming<br>\n",
    "- Train-test split accuracy: 0.5<br>\n",
    "- Leave-one-out split accuracy: 0.7666666666666667\n",
    "<h4>English</h4>\n",
    "+ With stemming<br>\n",
    "- Train-test split accuracy: 0.6060606060606061<br>\n",
    "- Leave-one-out split accuracy: 0.6305806153134398<br>\n",
    "+ Without stemming<br>\n",
    "- Train-test split accuracy: 0.6060606060606061<br>\n",
    "- Leave-one-out split accuracy: 0.6382142030996993<br>\n",
    "\n",
    "<h2>Word2vec</h2>\n",
    "<h4>Small Turkish</h4>\n",
    "+ With stemming<br>\n",
    "- Train-test split accuracy: 0.25<br>\n",
    "- Leave-one-out split accuracy: 0.48333333333333334<br>\n",
    "+ Without stemming<br>\n",
    "- Train-test split accuracy: 0.25<br>\n",
    "- Leave-one-out split accuracy: 0.75\n",
    "<h4>Big Turkish</h4>\n",
    "+ With stemming<br>\n",
    "- Train-test split accuracy: 0.5<br>\n",
    "- Leave-one-out split accuracy: 0.7666666666666667<br>\n",
    "+ Without stemming<br>\n",
    "- Train-test split accuracy: 0.25<br>\n",
    "- Leave-one-out split accuracy: 0.6166666666666667\n",
    "<h4>English</h4>\n",
    "+ With stemming<br>\n",
    "- Train-test split accuracy: 0.75<br>\n",
    "- Leave-one-out split accuracy: 0.6377952755905512<br>\n",
    "+ Without stemming<br>\n",
    "- Train-test split accuracy: 0.7272727272727273<br>\n",
    "- Leave-one-out split accuracy: 0.676923076923077<br>\n",
    "\n",
    "<h2>Available Word2vec words</h2>\n",
    "Small Turkish<br>\n",
    "- With stemming: 0.6872536136662286<br>\n",
    "- Without stemming: 0.668856767411301<br>\n",
    "Big Turkish<br>\n",
    "- With stemming: 0.8055190538764783<br>\n",
    "- Without stemming: 0.8620236530880421<br>\n",
    "English<br>\n",
    "- With stemming: 0.7068965517241379<br>\n",
    "- Without stemming: 0.9379310344827586<br>\n",
    "\n",
    "<h2>Word2vec model size/speed</h2>\n",
    "(refer to word2vec_speed.ipynb)<br>\n",
    "- Small Turkish: 86MB / 1.7109315395355225 seconds<br>\n",
    "- Big Turkish: 633MB / 3.560025215148926 seconds<br>\n",
    "- English model: 362MB / 2.4627420902252197 seconds<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abc404",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "The best result we got with the English dataset was using stemming, word2vec and train-test data split (75% accuracy).<br>\n",
    "In the Turkish dataset we got two ways of achieving best results (76% accuracy):<br>\n",
    "1- No stemming, tfidf, leave-one-out<br>\n",
    "2- Stemming, big word2vec model, leave-one-out<br>\n",
    "As the first method is both faster (no stemming and word2vec lookup required) and takes less space (no big word2vec model required), I decided that the first method is the best one for the Turkish dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9aaff4",
   "metadata": {},
   "source": [
    "The above results were all achieved with MultinomialNB. Now I will use different classification models and see which one will give the best results (using the best preprocessing steps I listed above for both datasets.)<br>\n",
    "\n",
    "<b>Turkish, no stemming, tfidf, leave-one-out</b><br>\n",
    "RandomForestClassifier accuracy: 0.7333333333333333<br>\n",
    "LinearSVC accuracy: 0.7333333333333333<br>\n",
    "MultinomialNB accuracy: 0.7333333333333333<br>\n",
    "LogisticRegression accuracy: 0.7333333333333333<br>\n",
    "\n",
    "<b>English, stemming, word2vec, train-test split</b><br>\n",
    "RandomForestClassifier accuracy: 0.6875<br>\n",
    "LinearSVC accuracy: 0.65625<br>\n",
    "MultinomialNB accuracy: 0.75<br>\n",
    "LogisticRegression accuracy: 0.6875<br>\n",
    "\n",
    "As we can see from above results, the classification model doesn't matter for the Turkish dataset as all training algorithms achieve the same results.<br>\n",
    "\n",
    "As for the English dataset, we can see that MultinomialNB gave us the best results compared to other models.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
