{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce871b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Load the embeddings\n",
    "loaded_ast_embeddings = torch.load('parsed_smell_embeddings.pt')\n",
    "\n",
    "# Load the message encoding vocabulary\n",
    "with open('message_encoding_vocabulary.pkl', 'rb') as file:\n",
    "    message_encoding_vocabulary = pickle.load(file)\n",
    "\n",
    "# Get a subset of message types for testing\n",
    "message_types = message_encoding_vocabulary[3:6]  # Change the range as needed\n",
    "\n",
    "# Randomly select 100 examples for testing\n",
    "example_indices = torch.randperm(loaded_ast_embeddings.shape[0])[:100]\n",
    "\n",
    "# Perform cosine similarity accuracy test\n",
    "correct_predictions = 0\n",
    "for index in example_indices:\n",
    "    embedding = loaded_ast_embeddings[index]\n",
    "    similarity_scores = util.cos_sim(embedding, loaded_ast_embeddings)\n",
    "\n",
    "    # Find the indices of top-k similar embeddings\n",
    "    _, top_indices = torch.topk(similarity_scores, k=len(message_types)+1)\n",
    "\n",
    "    # Check if the correct message type is among the top-k similar embeddings\n",
    "    if index in top_indices:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(example_indices)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ff923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Load the embeddings\n",
    "loaded_ast_embeddings = torch.load('parsed_smell_identifier_embeddings.pt')\n",
    "\n",
    "# Load the message encoding vocabulary\n",
    "with open('message_encoding_vocabulary.pkl', 'rb') as file:\n",
    "    message_encoding_vocabulary = pickle.load(file)\n",
    "\n",
    "# Get a subset of message types for testing\n",
    "message_types = message_encoding_vocabulary[3:6]  # Change the range as needed\n",
    "\n",
    "# Randomly select 100 examples for testing\n",
    "example_indices = torch.randperm(loaded_ast_embeddings.shape[0])[:100]\n",
    "\n",
    "# Perform cosine similarity accuracy test\n",
    "correct_predictions = 0\n",
    "for index in example_indices:\n",
    "    embedding = loaded_ast_embeddings[index]\n",
    "    similarity_scores = util.cos_sim(embedding, loaded_ast_embeddings)\n",
    "\n",
    "    # Find the indices of top-k similar embeddings\n",
    "    _, top_indices = torch.topk(similarity_scores, k=len(message_types)+1)\n",
    "\n",
    "    # Check if the correct message type is among the top-k similar embeddings\n",
    "    if index in top_indices:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(example_indices)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a58cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Decision Tree: 0.0\n",
      "Accuracy SVM: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the message encoding vocabulary\n",
    "with open('message_encoding_vocabulary.pkl', 'rb') as file:\n",
    "    message_encoding_vocabulary = pickle.load(file)\n",
    "\n",
    "# Get a subset of message types for testing\n",
    "message_types = message_encoding_vocabulary[3:6]  # Change the range as needed\n",
    "\n",
    "# Load the embeddings\n",
    "loaded_ast_embeddings = torch.load('parsed_smell_identifier_embeddings.pt')\n",
    "\n",
    "# Convert the message encoding vocabulary to a list\n",
    "message_encoding_vocabulary = message_encoding_vocabulary.tolist()\n",
    "\n",
    "# Get the indices of the selected message types in the vocabulary\n",
    "message_type_indices = np.where(np.isin(message_encoding_vocabulary, message_types))[0]\n",
    "\n",
    "# Select the embeddings for the selected message types\n",
    "selected_embeddings = loaded_ast_embeddings[message_type_indices]\n",
    "\n",
    "# Select a subset of the data (100 examples)\n",
    "subset_selected_embeddings = selected_embeddings[:100]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(subset_selected_embeddings, message_type_indices[:100],\n",
    "                                                    test_size=0.30, random_state=1)\n",
    "\n",
    "# Create Decision Tree classifier object\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Decision Tree:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
    "\n",
    "# Create SVM classifier object\n",
    "clf_svm = SVC(kernel='poly', degree=15, C=1.0)\n",
    "\n",
    "# Train SVM classifier\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy SVM:\", metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111b6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import indices\n",
    "from numpy.distutils.system_info import dfftw_info\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
    "from sklearn import metrics  # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import column_or_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d20b0",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfSolution(vekt√∂rler), dfClass(mesajlar), test_size=0.30,\n",
    "                                                        random_state=1)  # 70% training and 30% test\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train.to_numpy().ravel())\n",
    "    y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d533c30b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [315, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16464/609412295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdfSolution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloaded_ast_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdfClass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmessage_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m X_train, X_test, y_train, y_test = train_test_split(dfSolution, dfClass, test_size=0.30,\n\u001b[0m\u001b[0;32m     10\u001b[0m                                                         random_state=1)  # 70% training and 30% test\n",
      "\u001b[1;32mC:\\CodingEnv\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\CodingEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\CodingEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [315, 3]"
     ]
    }
   ],
   "source": [
    "with open('message_encoding_vocabulary.pkl', 'rb') as file:\n",
    "    message_encoding_vocabulary = pickle.load(file)\n",
    "\n",
    "loaded_ast_embeddings = torch.load('parsed_smell_identifier_embeddings.pt')\n",
    "\n",
    "message_types = message_encoding_vocabulary[3:6] \n",
    "dfSolution=loaded_ast_embeddings \n",
    "dfClass=message_types\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfSolution, dfClass, test_size=0.30,\n",
    "                                                        random_state=1)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b37599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_ast_embeddings.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de8bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
